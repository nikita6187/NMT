+------- PROLOGUE SCRIPT -----------------------------------------------
|
| Job ID ...........: 9679609
| Started at .......: Mon Aug  5 16:29:08 CEST 2019
| Execution host ...: cluster-cn-236
| Cluster queue ....: 4-GPU-1080
| Script ...........: /var/spool/sge/cluster-cn-236/job_scripts/9679609
| > YEAR=$1
| > CONFIG=$2
| > EPOCH=$3
| > BEAM_SIZE=$4
| > OUTPUT_FOLDER=$5
| > DIR_FOLDER=$6
| > 
| > shift
| > shift
| > shift
|
+------- PROLOGUE SCRIPT -----------------------------------------------
RETURNN get-attention-weights starting up.
RETURNN starting up, version unknown(git exception: CalledProcessError(128, ('git', 'show', '-s', '--format=%ci', 'HEAD'))), date/time 2019-08-05-16-29-14 (UTC+0200), pid 5178, cwd /work/smt3/bahar/expriments/wmt/2019/en-zh/returnn--2019-04-16/data-train/rnn-enc4-dropout3-hmm-k5, Python /u/bahar/settings/python3-returnn-tf1.9/bin/python3
RETURNN config: /u/bahar/workspace/wmt/2019/en-zh--2019-04-16/config-train/rnn-enc4-dropout3-hmm-k5.config
RETURNN command line options: ()
Hostname: cluster-cn-236
TensorFlow: 1.10.0 (v1.10.0-0-g656e7a2b34) (<site-package> in /u/bahar/settings/python3-returnn-tf1.9/lib/python3.5/site-packages/tensorflow)
Error while getting SGE num_proc: FileNotFoundError(2, "No such file or directory: 'qstat'")
Setup TF inter and intra global thread pools, num_threads None, session opts {'log_device_placement': False, 'device_count': {'GPU': 0}}.
CUDA_VISIBLE_DEVICES is set to '1'.
Collecting TensorFlow device list...
Local devices available to TensorFlow:
  1/2: name: "/device:CPU:0"
       device_type: "CPU"
       memory_limit: 268435456
       locality {
       }
       incarnation: 7479175505260442548
  2/2: name: "/device:GPU:0"
       device_type: "GPU"
       memory_limit: 10927236711
       locality {
         bus_id: 1
         links {
         }
       }
       incarnation: 9982995503731417271
       physical_device_desc: "device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1"
Using gpu device 1: GeForce GTX 1080 Ti
Device not set explicitly, and we found a GPU, which we will use.
Model file prefix: net-model/network
NOTE: We will use 'default' seq ordering.
<TranslationDataset 'dataset_id22783633730304' epoch=1>: waiting for data length info...
Setup tf.Session with options {'log_device_placement': False, 'device_count': {'GPU': 1}} ...
layer root/'data' output: Data(name='data', shape=(None,), dtype='int32', sparse=True, dim=32032)
layer root/'source_embed' output: Data(name='source_embed_output', shape=(None, 512))
debug_add_check_numerics_on_output: add for layer 'source_embed': <tf.Tensor 'source_embed/linear/embedding_lookup:0' shape=(?, ?, 512) dtype=float32>
layer root/'lstm0_fw' output: Data(name='lstm0_fw_output', shape=(None, 1000), batch_dim_axis=1)
OpCodeCompiler call: /usr/local/cuda-9.0/bin/nvcc -shared -O2 -std=c++11 -I /u/bahar/settings/python3-returnn-tf1.9/lib/python3.5/site-packages/tensorflow/include -I /u/bahar/settings/python3-returnn-tf1.9/lib/python3.5/site-packages/tensorflow/include/external/nsync/public -I /usr/local/cuda-9.0/include -L /usr/local/cuda-9.0/lib64 -x cu -v -DGOOGLE_CUDA=1 -Xcompiler -fPIC -Xcompiler -v -arch compute_61 -D_GLIBCXX_USE_CXX11_ABI=0 -g /var/tmp/9679609.1.4-GPU-1080/makarov/returnn_tf_cache/ops/NativeLstm2/807b76c5bb/NativeLstm2.cc -o /var/tmp/9679609.1.4-GPU-1080/makarov/returnn_tf_cache/ops/NativeLstm2/807b76c5bb/NativeLstm2.so -L/u/bahar/settings/python3-returnn-tf1.9/lib/python3.5/site-packages/numpy/.libs -l:libopenblasp-r0-39a31c03.2.18.so -L/u/bahar/settings/python3-returnn-tf1.9/lib/python3.5/site-packages/tensorflow -ltensorflow_framework
OpCodeCompiler call: /usr/local/cuda-9.0/bin/nvcc -shared -O2 -std=c++11 -I /u/bahar/settings/python3-returnn-tf1.9/lib/python3.5/site-packages/tensorflow/include -I /u/bahar/settings/python3-returnn-tf1.9/lib/python3.5/site-packages/tensorflow/include/external/nsync/public -I /usr/local/cuda-9.0/include -L /usr/local/cuda-9.0/lib64 -x cu -v -DGOOGLE_CUDA=1 -Xcompiler -fPIC -Xcompiler -v -arch compute_61 -D_GLIBCXX_USE_CXX11_ABI=0 -g /var/tmp/9679609.1.4-GPU-1080/makarov/returnn_tf_cache/ops/GradOfNativeLstm2/ef93791ddb/GradOfNativeLstm2.cc -o /var/tmp/9679609.1.4-GPU-1080/makarov/returnn_tf_cache/ops/GradOfNativeLstm2/ef93791ddb/GradOfNativeLstm2.so -L/u/bahar/settings/python3-returnn-tf1.9/lib/python3.5/site-packages/numpy/.libs -l:libopenblasp-r0-39a31c03.2.18.so -L/u/bahar/settings/python3-returnn-tf1.9/lib/python3.5/site-packages/tensorflow -ltensorflow_framework
debug_add_check_numerics_on_output: add for layer 'lstm0_fw': <tf.Tensor 'lstm0_fw/rec/NativeLstm2:0' shape=(?, ?, 1000) dtype=float32>
layer root/'lstm0_bw' output: Data(name='lstm0_bw_output', shape=(None, 1000), batch_dim_axis=1)
debug_add_check_numerics_on_output: add for layer 'lstm0_bw': <tf.Tensor 'lstm0_bw/rec/NativeLstm2:0' shape=(?, ?, 1000) dtype=float32>
layer root/'lstm1_fw' output: Data(name='lstm1_fw_output', shape=(None, 1000), batch_dim_axis=1)
debug_add_check_numerics_on_output: add for layer 'lstm1_fw': <tf.Tensor 'lstm1_fw/rec/NativeLstm2:0' shape=(?, ?, 1000) dtype=float32>
layer root/'lstm1_bw' output: Data(name='lstm1_bw_output', shape=(None, 1000), batch_dim_axis=1)
debug_add_check_numerics_on_output: add for layer 'lstm1_bw': <tf.Tensor 'lstm1_bw/rec/NativeLstm2:0' shape=(?, ?, 1000) dtype=float32>
layer root/'lstm2_fw' output: Data(name='lstm2_fw_output', shape=(None, 1000), batch_dim_axis=1)
debug_add_check_numerics_on_output: add for layer 'lstm2_fw': <tf.Tensor 'lstm2_fw/rec/NativeLstm2:0' shape=(?, ?, 1000) dtype=float32>
layer root/'lstm2_bw' output: Data(name='lstm2_bw_output', shape=(None, 1000), batch_dim_axis=1)
debug_add_check_numerics_on_output: add for layer 'lstm2_bw': <tf.Tensor 'lstm2_bw/rec/NativeLstm2:0' shape=(?, ?, 1000) dtype=float32>
layer root/'lstm3_fw' output: Data(name='lstm3_fw_output', shape=(None, 1000), batch_dim_axis=1)
debug_add_check_numerics_on_output: add for layer 'lstm3_fw': <tf.Tensor 'lstm3_fw/rec/NativeLstm2:0' shape=(?, ?, 1000) dtype=float32>
layer root/'lstm3_bw' output: Data(name='lstm3_bw_output', shape=(None, 1000), batch_dim_axis=1)
debug_add_check_numerics_on_output: add for layer 'lstm3_bw': <tf.Tensor 'lstm3_bw/rec/NativeLstm2:0' shape=(?, ?, 1000) dtype=float32>
layer root/'encoder' output: Data(name='encoder_output', shape=(None, 2000), batch_dim_axis=1)
debug_add_check_numerics_on_output: add for layer 'encoder': <tf.Tensor 'concat_lstm3_fw_lstm3_bw/concat_sources/concat:0' shape=(?, ?, 2000) dtype=float32>
layer root/'enc_ctx' output: Data(name='enc_ctx_output', shape=(None, 1000), batch_dim_axis=1)
debug_add_check_numerics_on_output: add for layer 'enc_ctx': <tf.Tensor 'enc_ctx/linear/add_bias:0' shape=(?, ?, 1000) dtype=float32>
layer root/'inv_fertility' output: Data(name='inv_fertility_output', shape=(None, 1), batch_dim_axis=1)
debug_add_check_numerics_on_output: add for layer 'inv_fertility': <tf.Tensor 'inv_fertility/activation/Sigmoid:0' shape=(?, ?, 1) dtype=float32>
layer root/'output' output: Data(name='output_output', shape=(None,), dtype='int32', sparse=True, dim=38568, batch_dim_axis=1)
Rec layer sub net:
  Input layers moved out of loop: (#: 2)
    output
    target_embed
  Output layers moved out of loop: (#: 4)
    output_prob
    base_encoder
    prev_outputs_transformed
    prev_state_transformed
  Layers in loop: (#: 10)
    att_weights
    energy
    energy_tanh
    energy_in
    prev_s_transformed
    prev_s_state
    s
    att
    weight_feedback
    accum_att_weights
  Unused layers: (#: 1)
    end
layer root/output:rec-subnet-input/'output' output: Data(name='classes', shape=(None,), dtype='int32', sparse=True, dim=38568)
layer root/output:rec-subnet-input/'target_embed' output: Data(name='target_embed_output', shape=(None, 512))
debug_add_check_numerics_on_output: add for layer 'target_embed': <tf.Tensor 'output/rec/target_embed/linear/embedding_lookup:0' shape=(?, ?, 512) dtype=float32>
layer root/output:rec-subnet/'weight_feedback' output: Data(name='weight_feedback_output', shape=(None, 1000), time_dim_axis=None)
debug_add_check_numerics_on_output: add for layer 'weight_feedback': <tf.Tensor 'output/rec/weight_feedback/linear/dot/Reshape_1:0' shape=(?, ?, 1000) dtype=float32>
layer root/output:rec-subnet/'prev_s_state' output: Data(name='prev_s_state_output', shape=(2000,), time_dim_axis=None)
debug_add_check_numerics_on_output: add for layer 'prev_s_state': <tf.Tensor 'output/rec/prev_s_state/concat:0' shape=(?, 2000) dtype=float32>
layer root/output:rec-subnet/'prev_s_transformed' output: Data(name='prev_s_transformed_output', shape=(1000,), time_dim_axis=None)
debug_add_check_numerics_on_output: add for layer 'prev_s_transformed': <tf.Tensor 'output/rec/prev_s_transformed/linear/dot/MatMul:0' shape=(?, 1000) dtype=float32>
layer root/output:rec-subnet/'energy_in' output: Data(name='energy_in_output', shape=(None, 1000), batch_dim_axis=1)
debug_add_check_numerics_on_output: add for layer 'energy_in': <tf.Tensor 'output/rec/energy_in/Add_1:0' shape=(?, ?, 1000) dtype=float32>
layer root/output:rec-subnet/'energy_tanh' output: Data(name='energy_tanh_output', shape=(None, 1000), batch_dim_axis=1)
debug_add_check_numerics_on_output: add for layer 'energy_tanh': <tf.Tensor 'output/rec/energy_tanh/activation/Tanh:0' shape=(?, ?, 1000) dtype=float32>
layer root/output:rec-subnet/'energy' output: Data(name='energy_output', shape=(None, 1), batch_dim_axis=1)
debug_add_check_numerics_on_output: add for layer 'energy': <tf.Tensor 'output/rec/energy/linear/dot/Reshape_1:0' shape=(?, ?, 1) dtype=float32>
layer root/output:rec-subnet/'att_weights' output: Data(name='att_weights_output', shape=(None, 1), batch_dim_axis=1)
debug_add_check_numerics_on_output: add for layer 'att_weights': <tf.Tensor 'output/rec/att_weights/tr_time_recover/transpose:0' shape=(?, ?, 1) dtype=float32>
layer root/output:rec-subnet/'accum_att_weights' output: Data(name='accum_att_weights_output', shape=(None, 1), time_dim_axis=None)
debug_add_check_numerics_on_output: add for layer 'accum_att_weights': <tf.Tensor 'output/rec/accum_att_weights/add:0' shape=(?, ?, 1) dtype=float32>
layer root/output:rec-subnet/'target_embed' output: Data(name='target_embed_output', shape=(512,), time_dim_axis=None)
debug_add_check_numerics_on_output: add for layer 'target_embed': <tf.Tensor 'output/rec/target_embed_moved_input/TensorArrayReadV3:0' shape=(?, 512) dtype=float32>
layer root/output:rec-subnet/'att' output: Data(name='att_output', shape=(2000,), time_dim_axis=None)
debug_add_check_numerics_on_output: add for layer 'att': <tf.Tensor 'output/rec/att/Reshape_1:0' shape=(?, 2000) dtype=float32>
layer root/output:rec-subnet/'s' output: Data(name='s_output', shape=(1000,), time_dim_axis=None)
debug_add_check_numerics_on_output: add for layer 's': <tf.Tensor 'output/rec/s/rec/lstm_cell/LSTMBlockCell:6' shape=(?, 1000) dtype=float32>
layer root/output:rec-subnet-output/'att_weights' output: Data(name='att_weights_output', shape=(None, None, 1), batch_dim_axis=2)
debug_add_check_numerics_on_output: add for layer 'att_weights': <tf.Tensor 'output/rec/att_weights/TensorArrayStack/TensorArrayGatherV3:0' shape=(?, ?, ?, 1) dtype=float32>
layer root/output:rec-subnet-output/'base_encoder' output: Data(name='base_encoder_output', shape=(None, 1000), batch_dim_axis=1)
debug_add_check_numerics_on_output: add for layer 'base_encoder': <tf.Tensor 'output/rec/base_encoder/linear/dot/Reshape_1:0' shape=(?, ?, 1000) dtype=float32>
layer root/output:rec-subnet-output/'prev_s_state' output: Data(name='prev_s_state_output', shape=(None, 2000), batch_dim_axis=1)
debug_add_check_numerics_on_output: add for layer 'prev_s_state': <tf.Tensor 'output/rec/prev_s_state/TensorArrayStack/TensorArrayGatherV3:0' shape=(?, ?, 2000) dtype=float32>
layer root/output:rec-subnet-output/'prev_state_transformed' output: Data(name='prev_state_transformed_output', shape=(None, 1000), batch_dim_axis=1)
debug_add_check_numerics_on_output: add for layer 'prev_state_transformed': <tf.Tensor 'output/rec/prev_state_transformed/linear/dot/Reshape_1:0' shape=(?, ?, 1000) dtype=float32>
layer root/output:rec-subnet-output/'prev:target_embed' output: Data(name='target_embed_output', shape=(None, 512), batch_dim_axis=1)
debug_add_check_numerics_on_output: add for layer 'prev:target_embed': <tf.Tensor 'output/rec/prev_target_embed/strided_slice:0' shape=(?, ?, 512) dtype=float32>
layer root/output:rec-subnet-output/'prev_outputs_transformed' output: Data(name='prev_outputs_transformed_output', shape=(None, 1000), batch_dim_axis=1)
debug_add_check_numerics_on_output: add for layer 'prev_outputs_transformed': <tf.Tensor 'output/rec/prev_outputs_transformed/linear/dot/Reshape_1:0' shape=(?, ?, 1000) dtype=float32>
layer root/output:rec-subnet-output/'output_prob' output: Data(name='att_weights_output', shape=(None, 38568), batch_dim_axis=1)
debug_add_check_numerics_on_output: add for layer 'output_prob': <tf.Tensor 'output/rec/output_prob/Squeeze_1:0' shape=(?, ?, 38568) dtype=float32>
layer root/'decision' output: Data(name='output_output', shape=(None,), dtype='int32', sparse=True, dim=38568, batch_dim_axis=1)
Warning: using numerical unstable sparse Cross-Entropy loss calculation
debug_add_check_numerics_on_output: add for layer loss 'output_prob': <tf.Tensor 'output/rec/output_prob/output_prob_identity_with_check_numerics_output/Identity:0' shape=(?, ?, 38568) dtype=float32>
Network layer topology:
  extern data: data: Data(shape=(None,), dtype='int32', sparse=True, dim=32032), classes: Data(shape=(None,), dtype='int32', sparse=True, dim=38568, available_for_inference=False)
  used data keys: ['classes', 'data']
  layer source 'data' #: 32032
  layer decide 'decision' #: 38568
  layer linear 'enc_ctx' #: 1000
  layer copy 'encoder' #: 2000
  layer linear 'inv_fertility' #: 1
  layer rec 'lstm0_bw' #: 1000
  layer rec 'lstm0_fw' #: 1000
  layer rec 'lstm1_bw' #: 1000
  layer rec 'lstm1_fw' #: 1000
  layer rec 'lstm2_bw' #: 1000
  layer rec 'lstm2_fw' #: 1000
  layer rec 'lstm3_bw' #: 1000
  layer rec 'lstm3_fw' #: 1000
  layer rec 'output' #: 38568
  layer linear 'source_embed' #: 512
net params #: 180412200
net trainable params: [<tf.Variable 'enc_ctx/W:0' shape=(2000, 1000) dtype=float32_ref>, <tf.Variable 'enc_ctx/b:0' shape=(1000,) dtype=float32_ref>, <tf.Variable 'inv_fertility/W:0' shape=(2000, 1) dtype=float32_ref>, <tf.Variable 'lstm0_bw/rec/W:0' shape=(512, 4000) dtype=float32_ref>, <tf.Variable 'lstm0_bw/rec/W_re:0' shape=(1000, 4000) dtype=float32_ref>, <tf.Variable 'lstm0_bw/rec/b:0' shape=(4000,) dtype=float32_ref>, <tf.Variable 'lstm0_fw/rec/W:0' shape=(512, 4000) dtype=float32_ref>, <tf.Variable 'lstm0_fw/rec/W_re:0' shape=(1000, 4000) dtype=float32_ref>, <tf.Variable 'lstm0_fw/rec/b:0' shape=(4000,) dtype=float32_ref>, <tf.Variable 'lstm1_bw/rec/W:0' shape=(2000, 4000) dtype=float32_ref>, <tf.Variable 'lstm1_bw/rec/W_re:0' shape=(1000, 4000) dtype=float32_ref>, <tf.Variable 'lstm1_bw/rec/b:0' shape=(4000,) dtype=float32_ref>, <tf.Variable 'lstm1_fw/rec/W:0' shape=(2000, 4000) dtype=float32_ref>, <tf.Variable 'lstm1_fw/rec/W_re:0' shape=(1000, 4000) dtype=float32_ref>, <tf.Variable 'lstm1_fw/rec/b:0' shape=(4000,) dtype=float32_ref>, <tf.Variable 'lstm2_bw/rec/W:0' shape=(2000, 4000) dtype=float32_ref>, <tf.Variable 'lstm2_bw/rec/W_re:0' shape=(1000, 4000) dtype=float32_ref>, <tf.Variable 'lstm2_bw/rec/b:0' shape=(4000,) dtype=float32_ref>, <tf.Variable 'lstm2_fw/rec/W:0' shape=(2000, 4000) dtype=float32_ref>, <tf.Variable 'lstm2_fw/rec/W_re:0' shape=(1000, 4000) dtype=float32_ref>, <tf.Variable 'lstm2_fw/rec/b:0' shape=(4000,) dtype=float32_ref>, <tf.Variable 'lstm3_bw/rec/W:0' shape=(2000, 4000) dtype=float32_ref>, <tf.Variable 'lstm3_bw/rec/W_re:0' shape=(1000, 4000) dtype=float32_ref>, <tf.Variable 'lstm3_bw/rec/b:0' shape=(4000,) dtype=float32_ref>, <tf.Variable 'lstm3_fw/rec/W:0' shape=(2000, 4000) dtype=float32_ref>, <tf.Variable 'lstm3_fw/rec/W_re:0' shape=(1000, 4000) dtype=float32_ref>, <tf.Variable 'lstm3_fw/rec/b:0' shape=(4000,) dtype=float32_ref>, <tf.Variable 'output/rec/base_encoder/W:0' shape=(1000, 1000) dtype=float32_ref>, <tf.Variable 'output/rec/energy/W:0' shape=(1000, 1) dtype=float32_ref>, <tf.Variable 'output/rec/output_prob/dense/kernel:0' shape=(1000, 38568) dtype=float32_ref>, <tf.Variable 'output/rec/prev_outputs_transformed/W:0' shape=(512, 1000) dtype=float32_ref>, <tf.Variable 'output/rec/prev_s_transformed/W:0' shape=(2000, 1000) dtype=float32_ref>, <tf.Variable 'output/rec/prev_state_transformed/W:0' shape=(2000, 1000) dtype=float32_ref>, <tf.Variable 'output/rec/s/rec/lstm_cell/bias:0' shape=(4000,) dtype=float32_ref>, <tf.Variable 'output/rec/s/rec/lstm_cell/kernel:0' shape=(3512, 4000) dtype=float32_ref>, <tf.Variable 'output/rec/target_embed/W:0' shape=(38568, 512) dtype=float32_ref>, <tf.Variable 'output/rec/weight_feedback/W:0' shape=(1, 1000) dtype=float32_ref>, <tf.Variable 'source_embed/W:0' shape=(32032, 512) dtype=float32_ref>]
loading weights from net-model/network.164
TF: log_dir: /work/smt2/makarov/NMT/hmm-factorization/experiments/wmt2019/parnia-en-zh-rnn-k5/tf_log_dir/dataset_id22783633730304-164-2019-08-05-14-29-10
Note: There are still these uninitialized variables: ['learning_rate:0']
Exception PermissionError(13, 'Permission denied') in step 0.
Step meta information:
{'seq_idx': [0, 1, 2, 3, 4, 5, 6, 7],
 'seq_tag': ['line-0',
             'line-1',
             'line-2',
             'line-3',
             'line-4',
             'line-5',
             'line-6',
             'line-7']}
Feed dict:
  <tf.Tensor 'extern_data/placeholders/classes/classes:0' shape=(?, ?) dtype=int32>: shape (8, 71), dtype int32, min/max 0/31527, Data(name='classes', shape=(None,), dtype='int32', sparse=True, dim=38568, available_for_inference=False)
  <tf.Tensor 'extern_data/placeholders/classes/classes_dim0_size:0' shape=(?,) dtype=int32>: shape (8,), dtype int32, min/max 10/71
  <tf.Tensor 'extern_data/placeholders/data/data:0' shape=(?, ?) dtype=int32>: shape (8, 72), dtype int32, min/max 0/31848, Data(name='data', shape=(None,), dtype='int32', sparse=True, dim=32032)
  <tf.Tensor 'extern_data/placeholders/data/data_dim0_size:0' shape=(?,) dtype=int32>: shape (8,), dtype int32, min/max 9/72
  <tf.Tensor 'extern_data/placeholders/seq_idx/seq_idx:0' shape=(?,) dtype=int32>: type <class 'list'>, Data(name='seq_idx', shape=(), dtype='int32', time_dim_axis=None)
  <tf.Tensor 'extern_data/placeholders/seq_tag/seq_tag:0' shape=(?,) dtype=string>: type <class 'list'>, Data(name='seq_tag', shape=(), dtype='string', time_dim_axis=None)
  <tf.Tensor 'globals/train_flag:0' shape=() dtype=bool>: type <class 'bool'>
Layer 'att_weights' Stats:
  8 seqs, 40896 total frames, 5112.000000 average frames
  Mean: 0.013888888888888888
  Std dev: 0.09648472491724061
  Min/max: 0.0 / 0.9999651
Some error occured, not finalized.
+------- EPILOGUE SCRIPT -----------------------------------------------
|
| Job ID ..............: 9679609
| Stopped at ..........: Mon Aug  5 16:30:32 CEST 2019
| Resources requested .: num_proc=5,scratch_free=5G,h_fsize=20G,h_rss=10G,h_rt=3600,gpu=1,s_core=0,pxe=ubuntu_16.04,h_vmem=1536G
| Resources used ......: cpu=00:00:30, mem=16.43406 GB s, io=0.70021 GB, vmem=1.156G, maxvmem=1.799G, last_file_cache=1.566G, last_rss=3M, max-cache=2.022G
| Memory used .........: 3.588G / 10.000G (35.9%)
| Total time used .....: 0:01:24
|
+------- EPILOGUE SCRIPT -----------------------------------------------
